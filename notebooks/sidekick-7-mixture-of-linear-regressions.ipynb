{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sidekick - Mixture of Least Squares\n",
    "We train a mixture of least squares, experimenting with different number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../utils/')) # Add sibling to Python path\n",
    "sys.path.insert(0, os.path.abspath('../src/')) # Add sibling to Python path\n",
    "sys.stdout.flush() # Print output on the fly in Notebook\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (16,14)\n",
    "matplotlib.rcParams['font.size'] = 16\n",
    "matplotlib.rcParams['legend.fontsize'] = 16\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pickle as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import Sidekick\n",
    "from model import LeastSquaresMixture\n",
    "from math import floor\n",
    "\n",
    "DATA_DIR = \"../data/sidekick\"\n",
    "\n",
    "def subsample(t, granularity):\n",
    "    if granularity > 1.0 or granularity <= 0:\n",
    "        raise ValueError(\"granularity must be in ]0, 1]\")\n",
    "    t0 = 1\n",
    "    n_samples = int(np.ceil(granularity * t))\n",
    "    if n_samples == 1:\n",
    "        return [t]\n",
    "    else:\n",
    "        return np.linspace(t0, t, n_samples, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data set...\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "sk = Sidekick()\n",
    "sk.load()\n",
    "projects_train, projects_test = sk.split(threshold=0.7)\n",
    "total = len(projects_train) + len(projects_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 7.11% outliers\n",
      "Training on 10343 projects (70.04%)\n",
      "Testing on 4425 projects (29.96%)\n",
      "Number of features: 3\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "t = 25\n",
    "granularity = 0.1\n",
    "T = 999\n",
    "\n",
    "samples = subsample(t, granularity)\n",
    "t = len(samples)\n",
    "#print(\"Samples ({}): {}\".format(t, samples))\n",
    "\n",
    "#N_projects = sk.choose_n_projects(n=N, seed=seed)\n",
    "#projects_train = N_projects[:N_train]\n",
    "#projects_test = N_projects[N_train:]\n",
    "\n",
    "# Remove outliers\n",
    "outlier_threshold = 2  # Ignore the project whose total pledged money if more that o_t times their goal\n",
    "projects_train_filtered = [p for p in projects_train if np.all((p.money[T] - outlier_threshold) <= 0) and np.all((p.money[samples] - outlier_threshold) <= 0)]\n",
    "projects_test_filtered = [p for p in projects_test if np.all((p.money[T] - outlier_threshold) <= 0) and np.all((p.money[samples] - outlier_threshold) <= 0)]\n",
    "#projects_test_filtered = projects_test\n",
    "\n",
    "X_train = np.ndarray(shape=(len(projects_train_filtered), t), buffer=np.array([p.money[samples] for p in projects_train_filtered]), dtype=float) \n",
    "y_train = np.expand_dims(np.array([p.money[T] for p in projects_train_filtered]), axis=1)\n",
    "X_test = np.ndarray(shape=(len(projects_test_filtered), t), buffer=np.array([p.money[samples] for p in projects_test_filtered]), dtype=float) \n",
    "y_test = np.expand_dims(np.array([p.money[T] for p in projects_test_filtered]), axis=1)\n",
    "\n",
    "# Required to contain the prediction in a reasonable range\n",
    "# The problem arises when evaluating the likelihood in the expression for gamma_nk\n",
    "#X_max = np.max(X_train, axis=0)\n",
    "#X_train = X_train / X_max[np.newaxis, :]\n",
    "# Apply same preprocessing to testing set\n",
    "#X_test = X_test / X_max[np.newaxis, :]  \n",
    "\n",
    "total_filtered = len(X_train) + len(X_test)\n",
    "print(\"Removed %0.2f%% outliers\" % (100 - total_filtered / total * 100))\n",
    "print(\"Training on %s projects (%0.2f%%)\" % (len(X_train), len(X_train) / total_filtered * 100))\n",
    "print(\"Testing on %s projects (%0.2f%%)\" % (len(X_test), len(X_test) / total_filtered * 100))\n",
    "print(\"Number of features: %s\" % t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Starting EM algorithm for mixture of K=3 least squares models\n",
      "* Beta = [ 1.  1.  1.]\n",
      "* Lambda = 0\n",
      "* Running at most 25 iterations\n",
      "* Stopping when complete likelihood improves less than 1\n",
      "       Obj       pi1       pi2       w11       w12       w21       w22     beta1     beta2\n",
      "      -inf      0.33      0.33      0.64      0.84      0.34      0.26      1.00      1.00\n",
      "  -1439.76      0.33      0.33      0.43      0.14      0.36      0.11      1.22      1.22\n",
      "   -382.31      0.33      0.33      0.42      0.14      0.40      0.14      1.48      1.48\n",
      "    315.52      0.33      0.33      0.41      0.15      0.41      0.16      1.49      1.48\n",
      "    323.74      0.33      0.33      0.41      0.16      0.41      0.18      1.49      1.48\n",
      "    324.33      0.33      0.33      0.41      0.17      0.41      0.21      1.49      1.48\n",
      "Model:        LeastSquaresMixture (3 components)\n",
      "Likelihood:   324.33057832812347\n",
      "Beta:         [ 1.4877509   1.48042175  1.49007769]\n",
      "Lambda:       0\n",
      "Pi:           [ 0.33370735  0.3320634   0.33422925]\n",
      "Weights norm: [3.0201937125600598, 3.0932368560489643, 2.9053177372370769]\n",
      "[[ 0.41328545  0.41321986  0.41012426]\n",
      " [ 0.16914728  0.20772525 -0.01293615]\n",
      " [-0.55693435 -0.64844333 -0.32854039]\n",
      " [ 2.93461727  2.98893544  2.85736996]]\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "beta = 1 / np.var(y_train) / K\n",
    "epsilon = 1\n",
    "lam = 0\n",
    "iterations = 25\n",
    "random_restarts = None\n",
    "\n",
    "mls1 = LeastSquaresMixture(X_train, y_train, \n",
    "                          K=K, beta=beta, lam=lam, \n",
    "                          iterations=iterations, epsilon=epsilon, random_restarts=random_restarts)\n",
    "mls1.train(verbose=True)\n",
    "\n",
    "print(mls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Starting EM algorithm for mixture of K=5 least squares models\n",
      "* Beta = [ 0.61506604  0.61506604  0.61506604  0.61506604  0.61506604]\n",
      "* Lambda = 0\n",
      "* Running at most 25 iterations\n",
      "* Stopping when complete likelihood improves less than 1.0\n",
      "       Obj       pi1       pi2       w11       w12       w21       w22     beta1     beta2\n",
      "      -inf      0.20      0.20      0.50      0.01      0.98      0.45      0.62      0.62\n",
      "  -3591.33      0.20      0.19      0.41      0.09      0.49      0.07      0.63      0.60\n",
      "  -3233.79      0.21      0.19      0.41      0.10      0.42      0.10      0.92      0.85\n",
      "  -1646.26      0.21      0.19      0.41      0.10      0.42      0.13      0.94      0.84\n",
      "  -1617.75      0.21      0.18      0.41      0.09      0.42      0.15      0.95      0.82\n",
      "  -1607.03      0.22      0.18      0.41      0.07      0.42      0.18      0.98      0.79\n",
      "  -1586.98      0.23      0.17      0.41      0.05      0.42      0.21      1.01      0.75\n",
      "  -1548.81      0.24      0.16      0.40      0.03      0.43      0.26      1.06      0.69\n",
      "  -1477.57      0.25      0.14      0.40     -0.01      0.43      0.31      1.13      0.62\n",
      "  -1349.27      0.27      0.12      0.40     -0.05      0.44      0.38      1.21      0.53\n",
      "  -1131.93      0.30      0.09      0.39     -0.09      0.46      0.47      1.33      0.41\n",
      "   -799.40      0.33      0.06      0.39     -0.13      0.47      0.57      1.46      0.28\n",
      "   -364.83      0.36      0.03      0.39     -0.17      0.50      0.65      1.61      0.16\n",
      "     91.14      0.39      0.01      0.39     -0.23      0.52      0.68      1.75      0.06\n",
      "    463.82      0.41      0.00      0.39     -0.29      0.53      0.65      1.87      0.02\n",
      "    730.89      0.43      0.00      0.39     -0.31      0.54      0.64      1.98      0.00\n",
      "    953.13      0.45      0.00      0.39     -0.29      0.56      0.67      2.08      0.00\n",
      "   1170.92      0.47      0.00      0.40     -0.22      0.57      0.72      2.15      0.00\n",
      "   1366.90      0.48      0.00      0.41     -0.05      0.59      0.81      2.18      0.00\n",
      "   1501.19      0.49      0.00      0.42      0.24      0.60      0.95      2.18      0.00\n",
      "   1559.12      0.49      0.00      0.43      0.46      0.60      0.92      2.18      0.00\n",
      "   1584.19      0.48      0.00      0.43      0.57      0.59      0.71      2.18      0.00\n",
      "   1610.08      0.48      0.00      0.44      0.59      0.59      0.56      2.17      0.00\n",
      "   1637.70      0.47      0.00      0.44      0.56      0.59      0.48      2.16      0.00\n",
      "   1663.18      0.46      0.00      0.45      0.52      0.59      0.46      2.14      0.00\n",
      "   1686.19      0.45      0.00      0.45      0.49      0.59      0.46      2.10      0.00\n",
      "Model:        LeastSquaresMixture (5 components)\n",
      "Likelihood:   1686.1938922193524\n",
      "Beta:         [  2.10131507e+000   8.72783842e-158   2.52589674e+000   4.60960239e-019\n",
      "   1.07458939e-162]\n",
      "Lambda:       0\n",
      "Pi:           [  4.54121219e-001   1.88619816e-158   5.45878781e-001   9.96194377e-020\n",
      "   2.32232592e-163]\n",
      "Weights norm: [2.5737114327405677, 1.5611987905033176, 3.8587744332657254, 1.561198790503378, 1.5611987905033078]\n",
      "[[ 0.45219151  0.58790455  0.35175934  0.58790455  0.58790455]\n",
      " [ 0.49398502  0.46052359 -1.07228076  0.46052359  0.46052359]\n",
      " [-0.59510743 -0.07363218  0.05711073 -0.07363218 -0.07363218]\n",
      " [ 2.41274518  1.36901652  3.68962841  1.36901652  1.36901652]]\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "beta = 1 / np.var(y_train) / K\n",
    "#beta = 0.0001\n",
    "epsilon = 1e0\n",
    "lam = 0\n",
    "iterations = 25\n",
    "random_restarts = None\n",
    "\n",
    "mls2 = LeastSquaresMixture(X_train, y_train, \n",
    "                          K=K, beta=beta, lam=lam, \n",
    "                          iterations=iterations, epsilon=epsilon, random_restarts=random_restarts)\n",
    "mls2.train(verbose=True)\n",
    "\n",
    "print(mls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Starting EM algorithm for mixture of K=10 least squares models\n",
      "* Beta = [ 0.30753302  0.30753302  0.30753302  0.30753302  0.30753302  0.30753302\n",
      "  0.30753302  0.30753302  0.30753302  0.30753302]\n",
      "* Lambda = 0\n",
      "* Running at most 25 iterations\n",
      "* Stopping when complete likelihood improves less than 1.0\n",
      "       Obj       pi1       pi2       w11       w12       w21       w22     beta1     beta2\n",
      "      -inf      0.10      0.10      0.84      0.66      0.75      0.25      0.31      0.31\n",
      "  -6632.16      0.10      0.10      0.44      0.12      0.43      0.11      0.30      0.30\n",
      "  -6525.34      0.10      0.10      0.41      0.13      0.41      0.13      0.44      0.45\n",
      "  -4701.62      0.10      0.10      0.41      0.13      0.41      0.13      0.44      0.45\n",
      "  -4694.51      0.10      0.10      0.41      0.13      0.41      0.13      0.44      0.45\n",
      "  -4693.07      0.10      0.10      0.41      0.13      0.41      0.13      0.44      0.45\n",
      "  -4690.11      0.10      0.10      0.41      0.13      0.41      0.13      0.43      0.45\n",
      "  -4683.89      0.10      0.10      0.41      0.13      0.41      0.12      0.43      0.45\n",
      "  -4670.83      0.09      0.10      0.41      0.14      0.41      0.12      0.42      0.45\n",
      "  -4643.48      0.09      0.10      0.41      0.14      0.41      0.13      0.41      0.45\n",
      "  -4586.51      0.09      0.10      0.42      0.15      0.41      0.13      0.39      0.45\n",
      "  -4469.42      0.08      0.10      0.42      0.17      0.41      0.13      0.36      0.45\n",
      "  -4235.24      0.07      0.10      0.42      0.19      0.42      0.15      0.32      0.44\n",
      "  -3791.89      0.06      0.09      0.43      0.24      0.42      0.18      0.27      0.42\n",
      "  -3032.84      0.04      0.08      0.44      0.32      0.43      0.25      0.19      0.37\n",
      "  -1926.71      0.02      0.06      0.47      0.42      0.45      0.37      0.11      0.28\n",
      "   -624.01      0.01      0.04      0.50      0.49      0.49      0.47      0.04      0.17\n",
      "    597.91      0.00      0.02      0.55      0.48      0.54      0.48      0.01      0.08\n",
      "   1520.32      0.00      0.00      0.61      0.43      0.60      0.43      0.00      0.02\n",
      "   2078.42      0.00      0.00      0.68      0.40      0.67      0.40      0.00      0.00\n",
      "   2346.69      0.00      0.00      0.74      0.38      0.74      0.38      0.00      0.00\n",
      "   2454.37      0.00      0.00      0.80      0.38      0.80      0.38      0.00      0.00\n",
      "   2496.53      0.00      0.00      0.85      0.41      0.85      0.41      0.00      0.00\n",
      "   2513.63      0.00      0.00      0.87      0.44      0.87      0.44      0.00      0.00\n",
      "   2520.38      0.00      0.00      0.86      0.45      0.86      0.45      0.00      0.00\n",
      "   2525.78      0.00      0.00      0.84      0.46      0.84      0.46      0.00      0.00\n",
      "Model:        LeastSquaresMixture (10 components)\n",
      "Likelihood:   2525.784256525347\n",
      "Beta:         [  6.19967855e-51   4.65552802e-27   8.08085570e-92   4.56716565e+00\n",
      "   1.32197486e-67   8.94361511e-11   9.46038681e-17   3.25141330e-68\n",
      "   1.16197006e-02   8.17006086e-39]\n",
      "Lambda:       0\n",
      "Pi:           [  1.35400070e-51   1.01676049e-27   1.76484703e-92   9.97462274e-01\n",
      "   2.88717369e-68   1.95327241e-11   2.06613460e-17   7.10103893e-69\n",
      "   2.53772555e-03   1.78432930e-39]\n",
      "Weights norm: [1.2853132642343621, 1.2853132642343585, 1.2853132642343663, 3.1224988758748271, 1.2853132642343381, 1.2853132638278619, 1.2853132642343221, 1.2853132642343899, 1.2852092751949886, 1.2853132642343736]\n",
      "[[ 0.8428716   0.8428716   0.8428716   0.39921037  0.8428716   0.8428716\n",
      "   0.8428716   0.8428716   0.84272461  0.8428716 ]\n",
      " [ 0.4553692   0.4553692   0.4553692  -0.34726909  0.4553692   0.4553692\n",
      "   0.4553692   0.4553692   0.45529301  0.4553692 ]\n",
      " [-0.29730963 -0.29730963 -0.29730963 -0.27899214 -0.29730963 -0.29730963\n",
      "  -0.29730963 -0.29730963 -0.29721482 -0.29730963]\n",
      " [ 0.80364391  0.80364391  0.80364391  3.06466929  0.80364391  0.80364391\n",
      "   0.80364391  0.80364391  0.80370999  0.80364391]]\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "beta = 1 / np.var(y_train) / K\n",
    "#beta = 0.0001\n",
    "epsilon = 1e0\n",
    "lam = 0\n",
    "iterations = 25\n",
    "random_restarts = None\n",
    "\n",
    "mls3 = LeastSquaresMixture(X_train, y_train, \n",
    "                          K=K, beta=beta, lam=lam, \n",
    "                          iterations=iterations, epsilon=epsilon, random_restarts=random_restarts)\n",
    "mls3.train(verbose=True)\n",
    "\n",
    "print(mls3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model LeastSquaresMixture (3 components)...\n",
      "Data point (4425/4425): [####################] 100% Elapsed time: 0:00:01\n",
      "Accuracy     : 0.6607909604519774\n",
      "RMSE         : 0.476572529804\n",
      "RMSE failed  : 0.363958046235\n",
      "RMSE success : 0.592610627489\n"
     ]
    }
   ],
   "source": [
    "rmse_failed, rmse_success, rmse, accuracy = mls1.evaluate(X_test, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model LeastSquaresMixture (5 components)...\n",
      "Data point (4425/4425): [####################] 100% Elapsed time: 0:00:01\n",
      "Accuracy     : 0.6612429378531074\n",
      "RMSE         : 0.47674950404\n",
      "RMSE failed  : 0.364561737375\n",
      "RMSE success : 0.592453165677\n"
     ]
    }
   ],
   "source": [
    "rmse_failed, rmse_success, rmse, accuracy = mls2.evaluate(X_test, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model LeastSquaresMixture (10 components)...\n",
      "Data point (4425/4425): [####################] 100% Elapsed time: 0:00:02\n",
      "Accuracy     : 0.6583050847457627\n",
      "RMSE         : 0.475436049003\n",
      "RMSE failed  : 0.365833458882\n",
      "RMSE success : 0.588976572683\n"
     ]
    }
   ],
   "source": [
    "rmse_failed, rmse_success, rmse, accuracy = mls3.evaluate(X_test, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model LeastSquaresMixture (3 components)...\n",
      "Data point (4425/4425): [####################] 100% Elapsed time: 0:00:07\n",
      "Accuracy     : 0.6508474576271186\n",
      "RMSE         : 0.47336519643\n",
      "RMSE failed  : 0.372801056501\n",
      "RMSE success : 0.579316591193\n"
     ]
    }
   ],
   "source": [
    "rmse_failed, rmse_success, rmse, accuracy = mls1.evaluate(X_test, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  0.844715677913\n",
      "Actual:     [ 1.02310255]\n"
     ]
    }
   ],
   "source": [
    "test = 12\n",
    "x_new = X_test[test]\n",
    "y_new = mls3.predict(x_new, posteriors=True)\n",
    "y_true = y_test[test]\n",
    "print(\"Predicted:  %s\" % y_new)\n",
    "#print(\"Posteriors: %s\" % [\"%0.2f%%\" % (p * 100) for p in y_posteriors])\n",
    "print(\"Actual:     %s\" % y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
