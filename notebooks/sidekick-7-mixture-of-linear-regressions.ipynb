{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sidekick - Mixture of Least Squares\n",
    "We train a mixture of least squares, experimenting with different number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../utils/')) # Add sibling to Python path\n",
    "sys.path.insert(0, os.path.abspath('../src/')) # Add sibling to Python path\n",
    "sys.stdout.flush() # Print output on the fly in Notebook\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (16,14)\n",
    "matplotlib.rcParams['font.size'] = 16\n",
    "matplotlib.rcParams['legend.fontsize'] = 16\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pickle as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import Sidekick\n",
    "from model import LeastSquaresMixture\n",
    "from math import floor\n",
    "\n",
    "DATA_DIR = \"../data/sidekick\"\n",
    "\n",
    "def subsample(t, granularity):\n",
    "    if granularity > 1.0 or granularity <= 0:\n",
    "        raise ValueError(\"granularity must be in ]0, 1]\")\n",
    "    t0 = 1\n",
    "    n_samples = int(np.ceil(granularity * t))\n",
    "    if n_samples == 1:\n",
    "        return [t]\n",
    "    else:\n",
    "        return np.linspace(t0, t, n_samples, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data set...\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "sk = Sidekick()\n",
    "sk.load()\n",
    "projects_train, projects_test = sk.split(threshold=0.7)\n",
    "total = len(projects_train) + len(projects_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 7.11% outliers\n",
      "Training on 10343 projects (70.04%)\n",
      "Testing on 4425 projects (29.96%)\n",
      "Number of features: 3\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "t = 25\n",
    "granularity = 0.1\n",
    "T = 999\n",
    "\n",
    "samples = subsample(t, granularity)\n",
    "t = len(samples)\n",
    "#print(\"Samples ({}): {}\".format(t, samples))\n",
    "\n",
    "#N_projects = sk.choose_n_projects(n=N, seed=seed)\n",
    "#projects_train = N_projects[:N_train]\n",
    "#projects_test = N_projects[N_train:]\n",
    "\n",
    "# Remove outliers\n",
    "outlier_threshold = 2  # Ignore the project whose total pledged money if more that o_t times their goal\n",
    "projects_train_filtered = [p for p in projects_train if np.all((p.money[T] - outlier_threshold) <= 0) and np.all((p.money[samples] - outlier_threshold) <= 0)]\n",
    "projects_test_filtered = [p for p in projects_test if np.all((p.money[T] - outlier_threshold) <= 0) and np.all((p.money[samples] - outlier_threshold) <= 0)]\n",
    "#projects_test_filtered = projects_test\n",
    "\n",
    "X_train = np.ndarray(shape=(len(projects_train_filtered), t), buffer=np.array([p.money[samples] for p in projects_train_filtered]), dtype=float) \n",
    "y_train = np.expand_dims(np.array([p.money[T] for p in projects_train_filtered]), axis=1)\n",
    "X_test = np.ndarray(shape=(len(projects_test_filtered), t), buffer=np.array([p.money[samples] for p in projects_test_filtered]), dtype=float) \n",
    "y_test = np.expand_dims(np.array([p.money[T] for p in projects_test_filtered]), axis=1)\n",
    "\n",
    "# Required to contain the prediction in a reasonable range\n",
    "# The problem arises when evaluating the likelihood in the expression for gamma_nk\n",
    "#X_max = np.max(X_train, axis=0)\n",
    "#X_train = X_train / X_max[np.newaxis, :]\n",
    "# Apply same preprocessing to testing set\n",
    "#X_test = X_test / X_max[np.newaxis, :]  \n",
    "\n",
    "total_filtered = len(X_train) + len(X_test)\n",
    "print(\"Removed %0.2f%% outliers\" % (100 - total_filtered / total * 100))\n",
    "print(\"Training on %s projects (%0.2f%%)\" % (len(X_train), len(X_train) / total_filtered * 100))\n",
    "print(\"Testing on %s projects (%0.2f%%)\" % (len(X_test), len(X_test) / total_filtered * 100))\n",
    "print(\"Number of features: %s\" % t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Starting EM algorithm for mixture of K=2 least squares models\n",
      "* Beta = [ 0.0001  0.0001]\n",
      "* Lambda = 0\n",
      "* Running at most 25 iterations\n",
      "* Stopping when complete likelihood improves less than 1\n",
      "       Obj       pi1       pi2       w11       w12       w21       w22     beta1     beta2\n",
      "      -inf      0.50      0.50      0.62      0.93      0.32      0.42      0.00      0.00\n",
      " -47631.42      0.50      0.50      0.41      0.13      0.41      0.13      1.84      1.84\n",
      "   1021.39      0.50      0.50      0.41      0.13      0.41      0.13      2.23      2.23\n",
      "   1558.85      0.50      0.50      0.41      0.13      0.41      0.13      2.23      2.23\n",
      "   1558.85      0.50      0.50      0.41      0.13      0.41      0.13      2.23      2.23\n",
      "Model:        LeastSquaresMixture (2 components)\n",
      "Likelihood:   1558.8542171807542\n",
      "Beta:         [ 2.2287282   2.22873099]\n",
      "Lambda:       0\n",
      "Pi:           [ 0.49999969  0.50000031]\n",
      "Weights norm: [3.0030869865858283, 3.0030395073199494]\n",
      "[[ 0.41229054  0.41228747]\n",
      " [ 0.12588702  0.12577889]\n",
      " [-0.51454158 -0.51442485]\n",
      " [ 2.92710563  2.92708252]]\n"
     ]
    }
   ],
   "source": [
    "K = 2\n",
    "beta = 0.0001\n",
    "epsilon = 1\n",
    "lam = 0\n",
    "iterations = 25\n",
    "random_restarts = None\n",
    "\n",
    "mls1 = LeastSquaresMixture(X_train, y_train, \n",
    "                          K=K, beta=beta, lam=lam, \n",
    "                          iterations=iterations, epsilon=epsilon, random_restarts=random_restarts)\n",
    "mls1.train(verbose=True)\n",
    "\n",
    "print(mls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Starting EM algorithm for mixture of K=2 least squares models\n",
      "* Beta = [ 0.001  0.001]\n",
      "* Lambda = 0\n",
      "* Running at most 1000 iterations\n",
      "* Stopping when complete likelihood improves less than 1.0\n",
      "       Obj       pi1       pi2       w11       w12       w21       w22     beta1     beta2\n",
      "      -inf      0.50      0.50      0.97      0.41      0.57      0.67      0.00      0.00\n",
      " -43940.95      0.47      0.53      0.15     -0.12      0.17     -0.12      0.00      0.00\n",
      " -41647.29      0.46      0.54      0.16     -0.13      0.16     -0.13      5.27      6.23\n",
      "   6485.97      0.45      0.55      0.17     -0.13      0.15     -0.13      5.18      6.39\n",
      "   6516.00      0.43      0.57      0.18     -0.14      0.14     -0.12      5.04      6.55\n",
      "   6537.73      0.42      0.58      0.19     -0.15      0.14     -0.11      4.87      6.76\n",
      "   6568.95      0.40      0.60      0.20     -0.17      0.13     -0.10      4.67      7.02\n",
      "   6614.99      0.38      0.62      0.21     -0.18      0.13     -0.09      4.42      7.34\n",
      "   6680.18      0.35      0.65      0.23     -0.20      0.12     -0.08      4.12      7.74\n",
      "   6768.27      0.31      0.69      0.25     -0.22      0.12     -0.08      3.77      8.22\n",
      "   6881.25      0.28      0.72      0.28     -0.24      0.11     -0.07      3.38      8.79\n",
      "   7016.12      0.24      0.76      0.32     -0.25      0.11     -0.07      2.96      9.45\n",
      "   7162.77      0.20      0.80      0.37     -0.27      0.11     -0.06      2.53     10.18\n",
      "   7304.94      0.16      0.84      0.43     -0.28      0.11     -0.06      2.13     10.93\n",
      "   7422.65      0.13      0.87      0.50     -0.29      0.11     -0.07      1.76     11.66\n",
      "   7502.67      0.11      0.89      0.58     -0.30      0.11     -0.07      1.45     12.27\n",
      "   7543.73      0.09      0.91      0.65     -0.31      0.11     -0.07      1.19     12.72\n",
      "   7553.69      0.07      0.93      0.71     -0.34      0.12     -0.08      0.97     12.96\n",
      "   7544.76      0.06      0.94      0.75     -0.37      0.12     -0.08      0.77     13.03\n",
      "Model:        LeastSquaresMixture (2 components)\n",
      "Likelihood:   7544.755864526023\n",
      "Beta:         [  0.77437584  13.02707565]\n",
      "Lambda:       0\n",
      "Pi:           [ 0.05610829  0.94389171]\n",
      "Weights norm: [22.451721815883538, 12.69408452478039]\n"
     ]
    }
   ],
   "source": [
    "K = 2\n",
    "beta = 0.001\n",
    "#beta = 0.0001\n",
    "epsilon = 1e0\n",
    "lam = 0\n",
    "iterations = 25\n",
    "random_restarts = None\n",
    "\n",
    "mls2 = LeastSquaresMixture(X_train, y_train, \n",
    "                          K=K, beta=beta, lam=lam, \n",
    "                          iterations=iterations, epsilon=epsilon, random_restarts=random_restarts)\n",
    "mls2.train(verbose=True)\n",
    "\n",
    "print(mls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Starting EM algorithm for mixture of K=2 least squares models\n",
      "* Beta = [ 0.0125  0.0125]\n",
      "* Lambda = 0\n",
      "* Running at most 25 iterations\n",
      "* Stopping when complete likelihood improves less than 1.0\n",
      "       Obj       pi1       pi2       w11       w12       w21       w22     beta1     beta2\n",
      "      -inf      0.50      0.50      0.95      0.32      0.98      0.49      0.01      0.01\n",
      " -40976.04      0.57      0.43      0.09      0.04      0.07      0.07      0.00      0.00\n",
      " -32628.10      0.60      0.40      0.08      0.05      0.08      0.05     13.42      8.97\n",
      "  10034.80      0.62      0.38      0.06      0.03      0.11      0.06     14.10      8.51\n",
      "  10153.33      0.65      0.35      0.05      0.02      0.13      0.08     15.04      8.01\n",
      "  10310.35      0.69      0.31      0.05      0.02      0.15      0.10     16.14      7.38\n",
      "  10494.93      0.72      0.28      0.05      0.02      0.18      0.11     17.47      6.65\n",
      "  10716.22      0.76      0.24      0.04      0.02      0.22      0.13     19.05      5.87\n",
      "  10965.42      0.80      0.20      0.04      0.02      0.26      0.15     20.90      5.11\n",
      "  11222.36      0.84      0.16      0.04      0.02      0.33      0.16     23.03      4.46\n",
      "  11465.72      0.86      0.14      0.04      0.02      0.40      0.18     25.42      3.98\n",
      "  11683.95      0.88      0.12      0.04      0.02      0.48      0.19     28.00      3.73\n",
      "  11878.02      0.89      0.11      0.03      0.02      0.55      0.18     30.63      3.71\n",
      "  12055.42      0.89      0.11      0.03      0.02      0.61      0.17     33.15      3.90\n",
      "  12222.80      0.89      0.11      0.03      0.02      0.65      0.14     35.45      4.27\n",
      "  12382.74      0.89      0.11      0.03      0.02      0.68      0.12     37.52      4.75\n",
      "  12535.27      0.88      0.12      0.03      0.03      0.70      0.10     39.44      5.32\n",
      "  12680.90      0.87      0.13      0.02      0.03      0.71      0.08     41.32      5.93\n",
      "  12822.52      0.87      0.13      0.02      0.03      0.73      0.06     43.30      6.60\n",
      "  12965.70      0.86      0.14      0.02      0.03      0.74      0.04     45.53      7.33\n",
      "  13117.94      0.86      0.14      0.02      0.04      0.76      0.03     48.18      8.17\n",
      "  13287.51      0.85      0.15      0.02      0.04      0.78      0.01     51.42      9.16\n",
      "  13481.46      0.84      0.16      0.02      0.05      0.81     -0.00     55.33     10.37\n",
      "  13701.68      0.83      0.17      0.01      0.06      0.82     -0.01     59.82     11.83\n",
      "  13938.88      0.83      0.17      0.01      0.06      0.84     -0.02     64.43     13.47\n",
      "  14169.56      0.82      0.18      0.01      0.07      0.85     -0.03     68.52     15.10\n",
      "Model:        LeastSquaresMixture (2 components)\n",
      "Likelihood:   14169.564586925724\n",
      "Beta:         [ 68.51604696  15.09749851]\n",
      "Lambda:       0\n",
      "Pi:           [ 0.81943717  0.18056283]\n",
      "Weights norm: [2.7714313847569327, 2.5998790877765137]\n"
     ]
    }
   ],
   "source": [
    "K = 2\n",
    "beta = 1 / t\n",
    "#beta = 0.0001\n",
    "epsilon = 1e0\n",
    "lam = 0\n",
    "iterations = 25\n",
    "random_restarts = None\n",
    "\n",
    "mls3 = LeastSquaresMixture(X_train, y_train, \n",
    "                          K=K, beta=beta, lam=lam, \n",
    "                          iterations=iterations, epsilon=epsilon, random_restarts=random_restarts)\n",
    "mls3.train(verbose=True)\n",
    "\n",
    "print(mls3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model LeastSquaresMixture (2 components)...\n",
      "Data point (4425/4425): [####################] 100% Elapsed time: 0:00:01\n",
      "Accuracy     : 0.7557062146892656\n",
      "RMSE         : 0.306295859076\n",
      "RMSE failed  : 0.174059819914\n",
      "RMSE success : 0.420801102719\n"
     ]
    }
   ],
   "source": [
    "rmse_failed, rmse_success, rmse, accuracy = mls1.evaluate(X_test, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model LeastSquaresMixture (2 components)...\n",
      "Data point (4424/4424): [####################] 100% Elapsed time: 0:00:02\n",
      "Accuracy     : 0.7597197106690777\n",
      "RMSE         : 0.312315056388\n",
      "RMSE failed  : 0.172204418002\n",
      "RMSE success : 0.431933022805\n"
     ]
    }
   ],
   "source": [
    "rmse_failed, rmse_success, rmse, accuracy = mls2.evaluate(X_test, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model LeastSquaresMixture (2 components)...\n",
      "Data point (4423/4423): [####################] 100% Elapsed time: 0:00:02\n",
      "Accuracy     : 0.8222925616097672\n",
      "RMSE         : 0.241792560369\n",
      "RMSE failed  : 0.186546328651\n",
      "RMSE success : 0.299186789879\n"
     ]
    }
   ],
   "source": [
    "rmse_failed, rmse_success, rmse, accuracy = mls3.evaluate(X_test, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model LeastSquaresMixture (2 components)...\n",
      "Data point (4423/4423): [####################] 100% Elapsed time: 0:00:01\n",
      "Accuracy     : 0.8182229256160977\n",
      "RMSE         : 0.223827117287\n",
      "RMSE failed  : 0.159197072235\n",
      "RMSE success : 0.287365328636\n"
     ]
    }
   ],
   "source": [
    "rmse_failed, rmse_success, rmse, accuracy = mls3.evaluate(X_test, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  0.844715677913\n",
      "Actual:     [ 1.02310255]\n"
     ]
    }
   ],
   "source": [
    "test = 12\n",
    "x_new = X_test[test]\n",
    "y_new = mls3.predict(x_new, posteriors=True)\n",
    "y_true = y_test[test]\n",
    "print(\"Predicted:  %s\" % y_new)\n",
    "#print(\"Posteriors: %s\" % [\"%0.2f%%\" % (p * 100) for p in y_posteriors])\n",
    "print(\"Actual:     %s\" % y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
