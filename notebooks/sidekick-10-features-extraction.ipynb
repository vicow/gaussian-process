{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sidekick - Features Extraction\n",
    "In this notebook, we try to find new features, mainly extracted from the backers and twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../utils/')) # Add sibling to Python path\n",
    "sys.path.insert(0, os.path.abspath('../src/')) # Add sibling to Python path\n",
    "sys.stdout.flush() # Print output on the fly in Notebook\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (16,8)\n",
    "#matplotlib.rcParams['figure.figsize'] = (20,20)\n",
    "matplotlib.rcParams['font.size'] = 32\n",
    "matplotlib.rcParams['legend.fontsize'] = 32\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pickle as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import Sidekick\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "def subsample(t, granularity):\n",
    "    if granularity > 1.0 or granularity <= 0:\n",
    "        raise ValueError(\"granularity must be in ]0, 1]\")\n",
    "    t0 = 0\n",
    "    n_samples = int(np.ceil(granularity * t))\n",
    "    if n_samples == 1:\n",
    "        return [t]\n",
    "    else:\n",
    "        return np.linspace(t0, t, n_samples, dtype=int)\n",
    "    \n",
    "def mean_increment(money):\n",
    "    d = np.diff(money)\n",
    "    increments = [i for i in d if i != 0]\n",
    "    if len(increments) > 0:\n",
    "        return np.mean(increments)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sk = Sidekick()\n",
    "sk.load(update=False)\n",
    "successful = sk.successful()\n",
    "failed = sk.failed()\n",
    "projects_train, projects_test = sk.split(threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outlier_threshold = 10000\n",
    "normalized = False\n",
    "\n",
    "for p in np.append(projects_train, projects_test):\n",
    "    p.normalized = normalized\n",
    "\n",
    "projects_train_filtered = [p for p in projects_train if np.all([(m - outlier_threshold) <= 0 for m in p.money])]\n",
    "projects_test_filtered = [p for p in projects_test if np.all([(m - outlier_threshold) <= 0 for m in p.money])]\n",
    "\n",
    "print(\"Keeping %.2f%% of data\" % (len(projects_train_filtered) / len(projects_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Money-based features\n",
    "We train the model for features extracted using the money time series up to time $t$ and using a level of granularity $\\gamma$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = 25\n",
    "granularity = 1\n",
    "samples = subsample(t, granularity)\n",
    "n_samples = 1\n",
    "\n",
    "T = 999\n",
    "standardize = False\n",
    "extractor1 = lambda a: a[t-1]\n",
    "extractor2 = lambda a: a[t-1] / t\n",
    "extractor3 = lambda a: mean_increment(a)\n",
    "extractor4 = lambda a: np.max(np.diff(a))\n",
    "\n",
    "processing = extractor1\n",
    "\n",
    "X_train = np.ndarray(shape=(len(projects_train_filtered), n_samples), buffer=np.array([processing(p.money[samples]) for p in projects_train_filtered]), dtype=float)\n",
    "y_train = np.expand_dims(np.array([p.money[T] for p in projects_train_filtered]), axis=1)\n",
    "X_test = np.ndarray(shape=(len(projects_test_filtered), n_samples), buffer=np.array([processing(p.money[samples]) for p in projects_test_filtered]), dtype=float)\n",
    "y_test = np.expand_dims(np.array([p.money[T] for p in projects_test_filtered]), axis=1)\n",
    "\n",
    "X_train_successful = [processing(p.money[samples]) for p in projects_train_filtered if p.successful]\n",
    "y_train_successful = [p.money[T] for p in projects_train_filtered if p.successful]\n",
    "X_train_failed = [processing(p.money[samples]) for p in projects_train_filtered if not p.successful]\n",
    "y_train_failed = [p.money[T] for p in projects_train_filtered if not p.successful]\n",
    "\n",
    "X_test_successful = [processing(p.money[samples]) for p in projects_test_filtered if p.successful]\n",
    "y_test_successful = [p.money[T] for p in projects_test_filtered if p.successful]\n",
    "X_test_failed = [processing(p.money[samples]) for p in projects_test_filtered if not p.successful]\n",
    "y_test_failed = [p.money[T] for p in projects_test_filtered if not p.successful]    \n",
    "\n",
    "if standardize:\n",
    "    X_train_mean = np.mean(X_train, axis=0)\n",
    "    X_train_std = np.std(X_train, axis=0)\n",
    "    X_train = (X_train - X_train_mean) / X_train_std\n",
    "    X_test = (X_test - X_train_mean) / X_train_std\n",
    "    \n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print('Linear regression: f(x) = %0.2f + %0.2fx' % (regr.intercept_[0], regr.coef_[0, 0]))\n",
    "\n",
    "print(\"Successful (train): %s (%.2f%%)\" % (len(X_train_successful), len(X_train_successful) / len(projects_train_filtered) * 100))\n",
    "print(\"Failed (train): %s (%.2f%%)\" % (len(X_train_failed), len(X_train_failed) / len(projects_train_filtered) * 100))\n",
    "\n",
    "print(\"Successful (test): %s (%.2f%%)\" % (len(X_test_successful), len(X_test_successful) / len(projects_test_filtered) * 100))\n",
    "print(\"Failed (test): %s (%.2f%%)\" % (len(X_test_failed), len(X_test_failed) / len(projects_test_filtered) * 100))\n",
    "\n",
    "plt.plot(X_train_successful, y_train_successful, 'xg')\n",
    "plt.plot(X_train_failed, y_train_failed, 'xr', alpha=0.2)\n",
    "\n",
    "#plt.plot(X_train, y_train, 'xb')\n",
    "\n",
    "x = np.linspace(plt.xlim()[0], plt.xlim()[1], 1000)\n",
    "y_pred = x * regr.coef_ + regr.intercept_\n",
    "plt.plot(x, y_pred[0], 'b-', lw=2)\n",
    "plt.title(\"Mean increments at time %s versus final amount\" % t)\n",
    "plt.xlabel(\"Average increment ($)\")\n",
    "plt.ylabel(\"Final amount ($)\")\n",
    "plt.xlim([0, plt.xlim()[1]])\n",
    "#plt.ylim([0, 1.5 * outlier_threshold])\n",
    "plt.savefig(\"increments_t_%s_linear_regression.pdf\" % t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "se_successful = []\n",
    "se_failed = []\n",
    "se_total = []\n",
    "accuracy = 0\n",
    "for i, x_test in enumerate(X_test):\n",
    "    if normalized:\n",
    "        goal = 1\n",
    "    else:\n",
    "        p = projects_test_filtered[i]\n",
    "        goal = float(p.goal)\n",
    "    x_test = np.expand_dims(x_test, axis=0)\n",
    "    #y_pred = x_test * regr.coef_ + regr.intercept_\n",
    "    y_pred = regr.predict(x_test)\n",
    "    y_pred = y_pred[0]\n",
    "    y_actual = y_test[i][0]\n",
    "    se = (y_pred - y_actual)**2\n",
    "    se_total.append(se)\n",
    "    if y_test[i] >= 1.0:  # Project is successful\n",
    "        se_successful.append(se)\n",
    "    else:  # project is failed\n",
    "        se_failed.append(se)\n",
    "    if normalized:\n",
    "        if (y_pred >= 1 and y_actual >= 1) or (y_pred < 1 and y_actual < 1):\n",
    "            accuracy += 1\n",
    "    else:\n",
    "        if (y_pred / goal >= 1 and y_actual / goal >= 1) or (y_pred / goal < 1 and y_actual / goal < 1):\n",
    "            accuracy += 1\n",
    "    #else:\n",
    "    #    print(\"Error:\", i)\n",
    "\n",
    "rmse_successful = np.sqrt(np.mean(se_successful))\n",
    "rmse_failed = np.sqrt(np.mean(se_failed))\n",
    "rmse_total = np.sqrt(np.mean(se_total))\n",
    "accuracy /= float(len(y_test))\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"RMSE: \", rmse_total)\n",
    "print(\"RMSE successful: \", rmse_successful)\n",
    "print(\"RMSE failed: \", rmse_failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
