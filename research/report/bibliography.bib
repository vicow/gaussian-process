@inproceedings{etter2013cosn,
	author = "Etter, Vincent and Grossglauser, Matthias and Thiran, Patrick",
	title = "Launch Hard or Go Home! Predicting the Success of Kickstarter Campaigns",
	booktitle = "Proceedings of the first ACM Conference on Online Social Networks",
	series = "COSN '13",
	year = "2013",
}

@book{Bishop:2006:PRM:1162264,
 author = {Bishop, Christopher M.},
 title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
 year = {2006},
 isbn = {0387310738},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
} 

@book{Rasmussen:2005:GPM:1162254,
 author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
 title = {Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)},
 year = {2005},
 isbn = {026218253X},
 publisher = {The MIT Press},
} 

@article{DBLP:journals/corr/FarajtabarWGLZS15,
  author    = {Mehrdad Farajtabar and
               Yichen Wang and
               Manuel Gomez{-}Rodriguez and
               Shuang Li and
               Hongyuan Zha and
               Le Song},
  title     = {{COEVOLVE:} {A} Joint Point Process Model for Information Diffusion
               and Network Co-evolution},
  journal   = {CoRR},
  volume    = {abs/1507.02293},
  year      = {2015},
  url       = {http://arxiv.org/abs/1507.02293},
  timestamp = {Sun, 02 Aug 2015 18:42:02 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/FarajtabarWGLZS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@ARTICLE{10.3389/fncom.2014.00038,
  
 AUTHOR={Jimenez Rezende, Danilo  and  Gerstner, Wulfram},   
	 
TITLE={Stochastic Variational Learning in Recurrent Spiking Networks},      
	
JOURNAL={Frontiers in Computational Neuroscience},      
	
VOLUME={8},      
	
YEAR={2014},      
	
NUMBER={38},     
	  
URL={http://www.frontiersin.org/computational_neuroscience/10.3389/fncom.2014.00038/abstract},       
	
DOI={10.3389/fncom.2014.00038},      
	
ISSN={1662-5188} ,      
	
ABSTRACT={The ability to learn and perform statistical inference with biologically plausible recurrent networks of spiking neurons is an important step toward understanding perception and reasoning. Here we derive and investigate a new learning rule for recurrent spiking networks with hidden neurons, combining principles from variational learning and reinforcement learning. Our network defines a generative model over spike train histories and the derived learning rule has the form of a local Spike Timing Dependent Plasticity rule modulated by global factors (neuromodulators) conveying information about “novelty” on a statistically rigorous ground. Simulations show that our model is able to learn both stationary and non-stationary patterns of spike trains. We also propose one experiment that could potentially be performed with animals in order to test the dynamics of the predicted novelty signal.}}